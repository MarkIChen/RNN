{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-stock-prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LU77a4-_2s8m",
        "wqh3yyCL391O",
        "8ezqUCGKzdsp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PblfPoP_zzug",
        "colab_type": "text"
      },
      "source": [
        "# Predict Stock Price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfmO9ZIUz48O",
        "colab_type": "text"
      },
      "source": [
        "Try to predict the downward and upward trend of Google stock price."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YpflIwP07Dq",
        "colab_type": "text"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L69GnTx_ztfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRb0vJ3Z1ARF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_url = 'https://raw.githubusercontent.com/MarkIChen/RNN/master/dataset/Google_Stock_Price_Train.csv'\n",
        "test_data_url = 'https://raw.githubusercontent.com/MarkIChen/RNN/master/dataset/Google_Stock_Price_Test.csv'\n",
        "train_data = pd.read_csv(train_data_url)\n",
        "test_data = pd.read_csv(test_data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB7GAxHU1jBS",
        "colab_type": "code",
        "outputId": "ecccbaf9-081a-41be-ad24-66ec9c4e1cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/3/2012</td>\n",
              "      <td>325.25</td>\n",
              "      <td>332.83</td>\n",
              "      <td>324.97</td>\n",
              "      <td>663.59</td>\n",
              "      <td>7,380,500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/4/2012</td>\n",
              "      <td>331.27</td>\n",
              "      <td>333.87</td>\n",
              "      <td>329.08</td>\n",
              "      <td>666.45</td>\n",
              "      <td>5,749,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/5/2012</td>\n",
              "      <td>329.83</td>\n",
              "      <td>330.75</td>\n",
              "      <td>326.89</td>\n",
              "      <td>657.21</td>\n",
              "      <td>6,590,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/6/2012</td>\n",
              "      <td>328.34</td>\n",
              "      <td>328.77</td>\n",
              "      <td>323.68</td>\n",
              "      <td>648.24</td>\n",
              "      <td>5,405,900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/9/2012</td>\n",
              "      <td>322.04</td>\n",
              "      <td>322.29</td>\n",
              "      <td>309.46</td>\n",
              "      <td>620.76</td>\n",
              "      <td>11,688,800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date    Open    High     Low   Close      Volume\n",
              "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
              "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
              "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
              "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
              "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1g5XRJD1tv5",
        "colab_type": "code",
        "outputId": "5a28c22d-96c8-4c3b-a233-12f8cfcebec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/3/2017</td>\n",
              "      <td>778.81</td>\n",
              "      <td>789.63</td>\n",
              "      <td>775.80</td>\n",
              "      <td>786.14</td>\n",
              "      <td>1,657,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/4/2017</td>\n",
              "      <td>788.36</td>\n",
              "      <td>791.34</td>\n",
              "      <td>783.16</td>\n",
              "      <td>786.90</td>\n",
              "      <td>1,073,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/5/2017</td>\n",
              "      <td>786.08</td>\n",
              "      <td>794.48</td>\n",
              "      <td>785.02</td>\n",
              "      <td>794.02</td>\n",
              "      <td>1,335,200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/6/2017</td>\n",
              "      <td>795.26</td>\n",
              "      <td>807.90</td>\n",
              "      <td>792.20</td>\n",
              "      <td>806.15</td>\n",
              "      <td>1,640,200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/9/2017</td>\n",
              "      <td>806.40</td>\n",
              "      <td>809.97</td>\n",
              "      <td>802.83</td>\n",
              "      <td>806.65</td>\n",
              "      <td>1,272,400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date    Open    High     Low   Close     Volume\n",
              "0  1/3/2017  778.81  789.63  775.80  786.14  1,657,300\n",
              "1  1/4/2017  788.36  791.34  783.16  786.90  1,073,000\n",
              "2  1/5/2017  786.08  794.48  785.02  794.02  1,335,200\n",
              "3  1/6/2017  795.26  807.90  792.20  806.15  1,640,200\n",
              "4  1/9/2017  806.40  809.97  802.83  806.65  1,272,400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU77a4-_2s8m",
        "colab_type": "text"
      },
      "source": [
        "## Prepare for training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qovv4N0B1zKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = train_data.iloc[:, 1:2].values\n",
        "# values will transform panda into a numpy array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipsYT2Mt3Od3",
        "colab_type": "code",
        "outputId": "81d847f8-c054-4c48-fef8-97c3d9bd0fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_data.shape, training_set.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1258, 6), (1258, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqh3yyCL391O",
        "colab_type": "text"
      },
      "source": [
        "## Feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46BX1kPL4lFZ",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://github.com/MarkIChen/RNN/blob/master/img/Feature-Scaling.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkvlYT0tyFNy",
        "colab_type": "text"
      },
      "source": [
        "When there is a sigmoid function as a activation layer, we should use normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNcZjmpo3QWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_TNHth5SG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKA7LR9u8QWP",
        "colab_type": "code",
        "outputId": "42c9f853-01ab-453c-d611-760dfb72ebac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "training_set_scaled.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ezqUCGKzdsp",
        "colab_type": "text"
      },
      "source": [
        "## Create a data structure to store timesteps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al9nUl9Xz4vo",
        "colab_type": "text"
      },
      "source": [
        "Now, we will predict the ouput based on privious 60 day data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rculP3T38YQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "y_train = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPzrJiYq0VKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(60, training_set_scaled.shape[0]-1):\n",
        "  X_train.append(training_set_scaled[i-60:i, 0])\n",
        "  y_train.append(training_set_scaled[i, 0])\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4e5OPeg13FN",
        "colab_type": "code",
        "outputId": "2cd7ea89-d2d4-46b4-915a-77ac942a26d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pd.DataFrame(X_train).head(5)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.085814</td>\n",
              "      <td>0.097012</td>\n",
              "      <td>0.094334</td>\n",
              "      <td>0.091562</td>\n",
              "      <td>0.079842</td>\n",
              "      <td>0.064328</td>\n",
              "      <td>0.058542</td>\n",
              "      <td>0.065686</td>\n",
              "      <td>0.061091</td>\n",
              "      <td>0.066393</td>\n",
              "      <td>0.061426</td>\n",
              "      <td>0.074745</td>\n",
              "      <td>0.027978</td>\n",
              "      <td>0.023793</td>\n",
              "      <td>0.024090</td>\n",
              "      <td>0.015924</td>\n",
              "      <td>0.010789</td>\n",
              "      <td>0.009673</td>\n",
              "      <td>0.016426</td>\n",
              "      <td>0.021002</td>\n",
              "      <td>0.022807</td>\n",
              "      <td>0.022732</td>\n",
              "      <td>0.028108</td>\n",
              "      <td>0.032127</td>\n",
              "      <td>0.043381</td>\n",
              "      <td>0.044758</td>\n",
              "      <td>0.047902</td>\n",
              "      <td>0.044069</td>\n",
              "      <td>0.046488</td>\n",
              "      <td>0.047455</td>\n",
              "      <td>0.048739</td>\n",
              "      <td>0.039363</td>\n",
              "      <td>0.041372</td>\n",
              "      <td>0.040349</td>\n",
              "      <td>0.047846</td>\n",
              "      <td>0.043251</td>\n",
              "      <td>0.043567</td>\n",
              "      <td>0.042860</td>\n",
              "      <td>0.046023</td>\n",
              "      <td>0.053985</td>\n",
              "      <td>0.057389</td>\n",
              "      <td>0.057147</td>\n",
              "      <td>0.055696</td>\n",
              "      <td>0.044218</td>\n",
              "      <td>0.045148</td>\n",
              "      <td>0.046060</td>\n",
              "      <td>0.044125</td>\n",
              "      <td>0.036759</td>\n",
              "      <td>0.044869</td>\n",
              "      <td>0.050655</td>\n",
              "      <td>0.052143</td>\n",
              "      <td>0.056124</td>\n",
              "      <td>0.058189</td>\n",
              "      <td>0.065407</td>\n",
              "      <td>0.068830</td>\n",
              "      <td>0.072438</td>\n",
              "      <td>0.079935</td>\n",
              "      <td>0.078466</td>\n",
              "      <td>0.080345</td>\n",
              "      <td>0.084977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.097012</td>\n",
              "      <td>0.094334</td>\n",
              "      <td>0.091562</td>\n",
              "      <td>0.079842</td>\n",
              "      <td>0.064328</td>\n",
              "      <td>0.058542</td>\n",
              "      <td>0.065686</td>\n",
              "      <td>0.061091</td>\n",
              "      <td>0.066393</td>\n",
              "      <td>0.061426</td>\n",
              "      <td>0.074745</td>\n",
              "      <td>0.027978</td>\n",
              "      <td>0.023793</td>\n",
              "      <td>0.024090</td>\n",
              "      <td>0.015924</td>\n",
              "      <td>0.010789</td>\n",
              "      <td>0.009673</td>\n",
              "      <td>0.016426</td>\n",
              "      <td>0.021002</td>\n",
              "      <td>0.022807</td>\n",
              "      <td>0.022732</td>\n",
              "      <td>0.028108</td>\n",
              "      <td>0.032127</td>\n",
              "      <td>0.043381</td>\n",
              "      <td>0.044758</td>\n",
              "      <td>0.047902</td>\n",
              "      <td>0.044069</td>\n",
              "      <td>0.046488</td>\n",
              "      <td>0.047455</td>\n",
              "      <td>0.048739</td>\n",
              "      <td>0.039363</td>\n",
              "      <td>0.041372</td>\n",
              "      <td>0.040349</td>\n",
              "      <td>0.047846</td>\n",
              "      <td>0.043251</td>\n",
              "      <td>0.043567</td>\n",
              "      <td>0.042860</td>\n",
              "      <td>0.046023</td>\n",
              "      <td>0.053985</td>\n",
              "      <td>0.057389</td>\n",
              "      <td>0.057147</td>\n",
              "      <td>0.055696</td>\n",
              "      <td>0.044218</td>\n",
              "      <td>0.045148</td>\n",
              "      <td>0.046060</td>\n",
              "      <td>0.044125</td>\n",
              "      <td>0.036759</td>\n",
              "      <td>0.044869</td>\n",
              "      <td>0.050655</td>\n",
              "      <td>0.052143</td>\n",
              "      <td>0.056124</td>\n",
              "      <td>0.058189</td>\n",
              "      <td>0.065407</td>\n",
              "      <td>0.068830</td>\n",
              "      <td>0.072438</td>\n",
              "      <td>0.079935</td>\n",
              "      <td>0.078466</td>\n",
              "      <td>0.080345</td>\n",
              "      <td>0.084977</td>\n",
              "      <td>0.086279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.094334</td>\n",
              "      <td>0.091562</td>\n",
              "      <td>0.079842</td>\n",
              "      <td>0.064328</td>\n",
              "      <td>0.058542</td>\n",
              "      <td>0.065686</td>\n",
              "      <td>0.061091</td>\n",
              "      <td>0.066393</td>\n",
              "      <td>0.061426</td>\n",
              "      <td>0.074745</td>\n",
              "      <td>0.027978</td>\n",
              "      <td>0.023793</td>\n",
              "      <td>0.024090</td>\n",
              "      <td>0.015924</td>\n",
              "      <td>0.010789</td>\n",
              "      <td>0.009673</td>\n",
              "      <td>0.016426</td>\n",
              "      <td>0.021002</td>\n",
              "      <td>0.022807</td>\n",
              "      <td>0.022732</td>\n",
              "      <td>0.028108</td>\n",
              "      <td>0.032127</td>\n",
              "      <td>0.043381</td>\n",
              "      <td>0.044758</td>\n",
              "      <td>0.047902</td>\n",
              "      <td>0.044069</td>\n",
              "      <td>0.046488</td>\n",
              "      <td>0.047455</td>\n",
              "      <td>0.048739</td>\n",
              "      <td>0.039363</td>\n",
              "      <td>0.041372</td>\n",
              "      <td>0.040349</td>\n",
              "      <td>0.047846</td>\n",
              "      <td>0.043251</td>\n",
              "      <td>0.043567</td>\n",
              "      <td>0.042860</td>\n",
              "      <td>0.046023</td>\n",
              "      <td>0.053985</td>\n",
              "      <td>0.057389</td>\n",
              "      <td>0.057147</td>\n",
              "      <td>0.055696</td>\n",
              "      <td>0.044218</td>\n",
              "      <td>0.045148</td>\n",
              "      <td>0.046060</td>\n",
              "      <td>0.044125</td>\n",
              "      <td>0.036759</td>\n",
              "      <td>0.044869</td>\n",
              "      <td>0.050655</td>\n",
              "      <td>0.052143</td>\n",
              "      <td>0.056124</td>\n",
              "      <td>0.058189</td>\n",
              "      <td>0.065407</td>\n",
              "      <td>0.068830</td>\n",
              "      <td>0.072438</td>\n",
              "      <td>0.079935</td>\n",
              "      <td>0.078466</td>\n",
              "      <td>0.080345</td>\n",
              "      <td>0.084977</td>\n",
              "      <td>0.086279</td>\n",
              "      <td>0.084716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.091562</td>\n",
              "      <td>0.079842</td>\n",
              "      <td>0.064328</td>\n",
              "      <td>0.058542</td>\n",
              "      <td>0.065686</td>\n",
              "      <td>0.061091</td>\n",
              "      <td>0.066393</td>\n",
              "      <td>0.061426</td>\n",
              "      <td>0.074745</td>\n",
              "      <td>0.027978</td>\n",
              "      <td>0.023793</td>\n",
              "      <td>0.024090</td>\n",
              "      <td>0.015924</td>\n",
              "      <td>0.010789</td>\n",
              "      <td>0.009673</td>\n",
              "      <td>0.016426</td>\n",
              "      <td>0.021002</td>\n",
              "      <td>0.022807</td>\n",
              "      <td>0.022732</td>\n",
              "      <td>0.028108</td>\n",
              "      <td>0.032127</td>\n",
              "      <td>0.043381</td>\n",
              "      <td>0.044758</td>\n",
              "      <td>0.047902</td>\n",
              "      <td>0.044069</td>\n",
              "      <td>0.046488</td>\n",
              "      <td>0.047455</td>\n",
              "      <td>0.048739</td>\n",
              "      <td>0.039363</td>\n",
              "      <td>0.041372</td>\n",
              "      <td>0.040349</td>\n",
              "      <td>0.047846</td>\n",
              "      <td>0.043251</td>\n",
              "      <td>0.043567</td>\n",
              "      <td>0.042860</td>\n",
              "      <td>0.046023</td>\n",
              "      <td>0.053985</td>\n",
              "      <td>0.057389</td>\n",
              "      <td>0.057147</td>\n",
              "      <td>0.055696</td>\n",
              "      <td>0.044218</td>\n",
              "      <td>0.045148</td>\n",
              "      <td>0.046060</td>\n",
              "      <td>0.044125</td>\n",
              "      <td>0.036759</td>\n",
              "      <td>0.044869</td>\n",
              "      <td>0.050655</td>\n",
              "      <td>0.052143</td>\n",
              "      <td>0.056124</td>\n",
              "      <td>0.058189</td>\n",
              "      <td>0.065407</td>\n",
              "      <td>0.068830</td>\n",
              "      <td>0.072438</td>\n",
              "      <td>0.079935</td>\n",
              "      <td>0.078466</td>\n",
              "      <td>0.080345</td>\n",
              "      <td>0.084977</td>\n",
              "      <td>0.086279</td>\n",
              "      <td>0.084716</td>\n",
              "      <td>0.074541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.079842</td>\n",
              "      <td>0.064328</td>\n",
              "      <td>0.058542</td>\n",
              "      <td>0.065686</td>\n",
              "      <td>0.061091</td>\n",
              "      <td>0.066393</td>\n",
              "      <td>0.061426</td>\n",
              "      <td>0.074745</td>\n",
              "      <td>0.027978</td>\n",
              "      <td>0.023793</td>\n",
              "      <td>0.024090</td>\n",
              "      <td>0.015924</td>\n",
              "      <td>0.010789</td>\n",
              "      <td>0.009673</td>\n",
              "      <td>0.016426</td>\n",
              "      <td>0.021002</td>\n",
              "      <td>0.022807</td>\n",
              "      <td>0.022732</td>\n",
              "      <td>0.028108</td>\n",
              "      <td>0.032127</td>\n",
              "      <td>0.043381</td>\n",
              "      <td>0.044758</td>\n",
              "      <td>0.047902</td>\n",
              "      <td>0.044069</td>\n",
              "      <td>0.046488</td>\n",
              "      <td>0.047455</td>\n",
              "      <td>0.048739</td>\n",
              "      <td>0.039363</td>\n",
              "      <td>0.041372</td>\n",
              "      <td>0.040349</td>\n",
              "      <td>0.047846</td>\n",
              "      <td>0.043251</td>\n",
              "      <td>0.043567</td>\n",
              "      <td>0.042860</td>\n",
              "      <td>0.046023</td>\n",
              "      <td>0.053985</td>\n",
              "      <td>0.057389</td>\n",
              "      <td>0.057147</td>\n",
              "      <td>0.055696</td>\n",
              "      <td>0.044218</td>\n",
              "      <td>0.045148</td>\n",
              "      <td>0.046060</td>\n",
              "      <td>0.044125</td>\n",
              "      <td>0.036759</td>\n",
              "      <td>0.044869</td>\n",
              "      <td>0.050655</td>\n",
              "      <td>0.052143</td>\n",
              "      <td>0.056124</td>\n",
              "      <td>0.058189</td>\n",
              "      <td>0.065407</td>\n",
              "      <td>0.068830</td>\n",
              "      <td>0.072438</td>\n",
              "      <td>0.079935</td>\n",
              "      <td>0.078466</td>\n",
              "      <td>0.080345</td>\n",
              "      <td>0.084977</td>\n",
              "      <td>0.086279</td>\n",
              "      <td>0.084716</td>\n",
              "      <td>0.074541</td>\n",
              "      <td>0.078838</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        57        58        59\n",
              "0  0.085814  0.097012  0.094334  ...  0.078466  0.080345  0.084977\n",
              "1  0.097012  0.094334  0.091562  ...  0.080345  0.084977  0.086279\n",
              "2  0.094334  0.091562  0.079842  ...  0.084977  0.086279  0.084716\n",
              "3  0.091562  0.079842  0.064328  ...  0.086279  0.084716  0.074541\n",
              "4  0.079842  0.064328  0.058542  ...  0.084716  0.074541  0.078838\n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnw6u7Qc2He9",
        "colab_type": "code",
        "outputId": "7257c779-56ec-4cc4-c70a-aafc56a7ed77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pd.DataFrame(y_train).head(5)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.086279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.084716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.074541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.078838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.072383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0\n",
              "0  0.086279\n",
              "1  0.084716\n",
              "2  0.074541\n",
              "3  0.078838\n",
              "4  0.072383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkC4R2vH5bR7",
        "colab_type": "text"
      },
      "source": [
        "## Reshaping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afl72Oy65dyL",
        "colab_type": "text"
      },
      "source": [
        "- Keras Recurrent Layers doc: \n",
        "3D tensor with shape (batch_size, timesteps, input_dim)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KYp3uro2NoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYFc6PmG6o6N",
        "colab_type": "code",
        "outputId": "7eb328ed-4fb4-4fb0-ddd6-23b4e009f22c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1197, 60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y64b8tIS9cfC",
        "colab_type": "text"
      },
      "source": [
        "## Build a RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnSBFKY59nNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BvfWurQ-Cz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To predict a continue value, we will use regression.\n",
        "regressor = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhhLqEvj-l4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The first Layer\n",
        "regressor.add(LSTM(units= 50, return_sequences= True, input_shape=(X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVQvIuDd-Yx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The second Layer\n",
        "regressor.add(LSTM(units= 50, return_sequences= True))\n",
        "regressor.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4eB-tBcEe-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The third Layer\n",
        "regressor.add(LSTM(units= 50, return_sequences= True))\n",
        "regressor.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUBzGrLrFr4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The forth Layer\n",
        "regressor.add(LSTM(units= 50, return_sequences= False))\n",
        "regressor.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0v2M8IvF_o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the output layer\n",
        "regressor.add(Dense(units=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0CYzSPkIvY7",
        "colab_type": "text"
      },
      "source": [
        "## Compile the model with arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grZDaQvSIzkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regressor.compile(optimizer='adam', loss= 'mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgXUyycZJ7vI",
        "colab_type": "text"
      },
      "source": [
        "## Train the model with data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPkLpiU5J7kB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0158aa2-ab22-4c96-a1da-394631374c88"
      },
      "source": [
        "regressor.fit(X_train, y_train, epochs= 100, batch_size= 32)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/100\n",
            "1197/1197 [==============================] - 13s 10ms/step - loss: 0.0624\n",
            "Epoch 2/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0067\n",
            "Epoch 3/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0054\n",
            "Epoch 4/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0056\n",
            "Epoch 5/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0053\n",
            "Epoch 6/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0048\n",
            "Epoch 7/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0052\n",
            "Epoch 8/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0050\n",
            "Epoch 9/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0048\n",
            "Epoch 10/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0046\n",
            "Epoch 11/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0042\n",
            "Epoch 12/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0048\n",
            "Epoch 13/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0038\n",
            "Epoch 14/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0041\n",
            "Epoch 15/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0032\n",
            "Epoch 16/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0037\n",
            "Epoch 17/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0036\n",
            "Epoch 18/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0038\n",
            "Epoch 19/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0035\n",
            "Epoch 20/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0033\n",
            "Epoch 21/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0038\n",
            "Epoch 22/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0033\n",
            "Epoch 23/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0031\n",
            "Epoch 24/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0032\n",
            "Epoch 25/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0033\n",
            "Epoch 26/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0034\n",
            "Epoch 27/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0032\n",
            "Epoch 28/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0032\n",
            "Epoch 29/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0032\n",
            "Epoch 30/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0029\n",
            "Epoch 31/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0026\n",
            "Epoch 32/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0029\n",
            "Epoch 33/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0028\n",
            "Epoch 34/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0028\n",
            "Epoch 35/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0030\n",
            "Epoch 36/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0029\n",
            "Epoch 37/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0030\n",
            "Epoch 38/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0028\n",
            "Epoch 39/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0025\n",
            "Epoch 40/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0027\n",
            "Epoch 41/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0030\n",
            "Epoch 42/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0025\n",
            "Epoch 43/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0025\n",
            "Epoch 44/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0026\n",
            "Epoch 45/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0026\n",
            "Epoch 46/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0025\n",
            "Epoch 47/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0024\n",
            "Epoch 48/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0023\n",
            "Epoch 49/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0023\n",
            "Epoch 50/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0025\n",
            "Epoch 51/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0026\n",
            "Epoch 52/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0023\n",
            "Epoch 53/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0023\n",
            "Epoch 54/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0022\n",
            "Epoch 55/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0024\n",
            "Epoch 56/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0022\n",
            "Epoch 57/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0023\n",
            "Epoch 58/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0022\n",
            "Epoch 59/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0020\n",
            "Epoch 60/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0022\n",
            "Epoch 61/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0024\n",
            "Epoch 62/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0020\n",
            "Epoch 63/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0019\n",
            "Epoch 64/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0020\n",
            "Epoch 65/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0022\n",
            "Epoch 66/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0020\n",
            "Epoch 67/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0019\n",
            "Epoch 68/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0018\n",
            "Epoch 69/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0018\n",
            "Epoch 70/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0019\n",
            "Epoch 71/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0020\n",
            "Epoch 72/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0018\n",
            "Epoch 73/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0021\n",
            "Epoch 74/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0020\n",
            "Epoch 75/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0016\n",
            "Epoch 76/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0020\n",
            "Epoch 77/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0017\n",
            "Epoch 78/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0016\n",
            "Epoch 79/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0018\n",
            "Epoch 80/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0017\n",
            "Epoch 81/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0016\n",
            "Epoch 82/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0016\n",
            "Epoch 83/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0017\n",
            "Epoch 84/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0018\n",
            "Epoch 85/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0017\n",
            "Epoch 86/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0017\n",
            "Epoch 87/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0015\n",
            "Epoch 88/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0015\n",
            "Epoch 89/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0015\n",
            "Epoch 90/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0016\n",
            "Epoch 91/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0015\n",
            "Epoch 92/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0015\n",
            "Epoch 93/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0018\n",
            "Epoch 94/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0015\n",
            "Epoch 95/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0015\n",
            "Epoch 96/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0015\n",
            "Epoch 97/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0015\n",
            "Epoch 98/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0014\n",
            "Epoch 99/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0015\n",
            "Epoch 100/100\n",
            "1197/1197 [==============================] - 8s 7ms/step - loss: 0.0014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76ce393f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oznSzJ2BOG6p",
        "colab_type": "text"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxP-wsAJJa5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_stock_price = test_data.iloc[:, 1:2].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wqMgf7HPr9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_total = pd.concat((train_data['Open'], test_data['Open']), axis= 0)\n",
        "inputs = data_total[len(data_total)-len(test_data) - 60 : ].values\n",
        "inputs = inputs.reshape(-1, 1)\n",
        "inputs = sc.transform(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCJ9k1FwT6E2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "367f4099-a8c7-408d-a5fb-db64e361a517"
      },
      "source": [
        "inputs.shape"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Cm5O30MStOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = []\n",
        "for i in range(60, 80):\n",
        "  X_test.append(inputs[i-60: i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiJfzcRQT_23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_stock_price = regressor.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvMhGk28UNRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "3adf4dc9-2693-4424-fa11-e7419b9afb8b"
      },
      "source": [
        "predicted_stock_price"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[773.4313 ],\n",
              "       [770.8076 ],\n",
              "       [770.5758 ],\n",
              "       [771.7064 ],\n",
              "       [774.8762 ],\n",
              "       [780.64056],\n",
              "       [786.45575],\n",
              "       [789.54395],\n",
              "       [790.3976 ],\n",
              "       [790.0763 ],\n",
              "       [789.3772 ],\n",
              "       [788.6126 ],\n",
              "       [788.03546],\n",
              "       [788.2486 ],\n",
              "       [789.0891 ],\n",
              "       [793.2614 ],\n",
              "       [800.02905],\n",
              "       [807.80176],\n",
              "       [812.8544 ],\n",
              "       [810.2513 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvUyrO6mUVJl",
        "colab_type": "text"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-VEf428UU0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "492078c1-89d2-46d1-dd9e-b306814cd57c"
      },
      "source": [
        "plt.plot(real_stock_price, color='red', label = 'Real Google Stock Price')\n",
        "plt.plot(predicted_stock_price, color='blue', label = 'Predicted Google Stock Price')\n",
        "plt.title('Google Stock Price Predicton')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwEis8Bj54cPpAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qhsvh9hUP-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}